##Model Train
# === Detect label column automatically ===
def detect_label_column(df):
    # Look for a column with few unique values (like 2-5 classes)
    for col in df.columns:
        if df[col].dtype != 'object' and df[col].nunique() <= 10:
            return col
        if df[col].dtype == 'object' and df[col].nunique() <= 5:
            return col
    raise ValueError("No label-like column found.")

label_col_train = detect_label_column(train_df)
label_col_test = detect_label_column(test_df)

print(f"Detected label column in train: {label_col_train}")
print(f"Detected label column in test: {label_col_test}")

y_train = train_df[label_col_train]
y_test = test_df[label_col_test]

# === 7. Feature extraction using TF-IDF ===
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=5000)
X_train = vectorizer.fit_transform(train_df['clean_review'])
X_test = vectorizer.transform(test_df['clean_review'])

# === 8. Logistic Regression ===
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

lr_model = LogisticRegression(max_iter=1000)
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)

print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Classification Report:\n" , classification_report(y_test, y_pred_lr))

# === 9. Naive Bayes ===
from sklearn.naive_bayes import MultinomialNB

nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)

print("Naive Bayes Accuracy:", accuracy_score(y_test, y_pred_nb))
print("Classification Report:\n", classification_report(y_test, y_pred_nb))

# === 10. Compare models ===
print("Comparison:")
print(f"Logistic Regression Accuracy: {accuracy_score(y_test, y_pred_lr)}")
print(f"Naive Bayes Accuracy: {accuracy_score(y_test, y_pred_nb)}")






