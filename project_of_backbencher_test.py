# -*- coding: utf-8 -*-
"""Project of backbencher test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z4smQwW9ZO_Kzov67o3OjGuxIMf21LMf

Data Preparation

Load the dataset in Python (Pandas or equivalent).
Clean the text:
Remove HTML tags, punctuation, and numbers
Convert to lowercase
Remove stopwords (NLTK or SpaCy)
Split into train (80%) and test (20%) sets.
"""

import pandas as pd
import re
import nltk
from nltk.corpus import stopwords

# Download stopwords (only needed once)
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# === 1. Load datasets ===
train_df = pd.read_csv("/content/train_data (1).csv")
test_df = pd.read_csv("/content/test_data (1).csv")

# Drop extra index columns if exist
train_df = train_df.drop(columns=['Unnamed: 0'], errors='ignore')
test_df = test_df.drop(columns=['Unnamed: 0'], errors='ignore')

# === 2. Detect review column automatically ===
def detect_review_column(df):
    for col in df.columns:
        # Check if column likely contains text reviews
        if df[col].dtype == 'object' and df[col].str.len().mean() > 20:
            return col
    raise ValueError("No review-like column found.")

review_col_train = detect_review_column(train_df)
review_col_test = detect_review_column(test_df)

print(f"Detected review column in train: {review_col_train}")
print(f"Detected review column in test: {review_col_test}")

# === 3. Text cleaning function ===
def clean_text(text):
    text = re.sub(r'<.*?>', '', text)              # remove HTML tags
    text = re.sub(r'[^a-zA-Z\s]', '', text)        # remove punctuation & numbers
    text = text.lower()                            # lowercase
    words = text.split()
    words = [w for w in words if w not in stop_words]  # remove stopwords
    return ' '.join(words)

# === 4. Apply cleaning ===
train_df['clean_review'] = train_df[review_col_train].apply(clean_text)
test_df['clean_review'] = test_df[review_col_test].apply(clean_text)

# === 5. Check cleaned data ===
print(train_df[['clean_review']].head())
print(test_df[['clean_review']].head())

# === detect label column automatically ===
def detect_label_column(df):
    # Look for a column with few unique values (like 2-5 classes)
    for col in df.columns:
        if df[col].dtype != 'object' and df[col].nunique() <= 10:
            return col
        if df[col].dtype == 'object' and df[col].nunique() <= 5:
            return col
    raise ValueError("No label-like column found.")

label_col_train = detect_label_column(train_df)
label_col_test = detect_label_column(test_df)

print(f"Detected label column in train: {label_col_train}")
print(f"Detected label column in test: {label_col_test}")

y_train = train_df[label_col_train]
y_test = test_df[label_col_test]

# === Feature extraction using TF-IDF ===
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=5000)
X_train = vectorizer.fit_transform(train_df['clean_review'])
X_test = vectorizer.transform(test_df['clean_review'])

# ===  logistic regression ===
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

lr_model = LogisticRegression(max_iter=1000)
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)

print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Classification Report: ", classification_report(y_test, y_pred_lr))

# === Naive Bayes ===
from sklearn.naive_bayes import MultinomialNB

nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)

print("Naive Bayes Accuracy:", accuracy_score(y_test, y_pred_nb))
print("Classification Report:", classification_report(y_test, y_pred_nb))

# === Compare models ===
print("Comparison:")
print(f"Logistic Regression Accuracy: {accuracy_score(y_test, y_pred_lr)}")
print(f"Naive Bayes Accuracy: {accuracy_score(y_test, y_pred_nb)}")

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import pickle
from sklearn.model_selection import GridSearchCV

# === Evaluate Logistic Regression ===
print("=== Logistic Regression Evaluation ===")
print("Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Classification Report: ", classification_report(y_test, y_pred_lr))

# Confusion matrix
cm_lr = confusion_matrix(y_test, y_pred_lr)
plt.figure(figsize=(6,5))
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Logistic Regression Confusion Matrix')
plt.show()

# === Naive Bayes ===
print("=== Naive Bayes Evaluation ===")
print("Accuracy:", accuracy_score(y_test, y_pred_nb))
print("Classification Report: ", classification_report(y_test, y_pred_nb))

# Confusion matrix
cm_nb = confusion_matrix(y_test, y_pred_nb)
plt.figure(figsize=(6,5))
sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Greens')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Naive Bayes Confusion Matrix')
plt.show()

# === Save the trained models and vectorizer ===
with open('tfidf_vectorizer.pkl', 'wb') as f:
    pickle.dump(vectorizer, f)

with open('logistic_model.pkl', 'wb') as f:
    pickle.dump(lr_model, f)

with open('naive_bayes_model.pkl', 'wb') as f:
    pickle.dump(nb_model, f)

print("Models and vectorizer saved as .pkl files.")

# === Optional: Logistic Regression Hyperparameter Tuning ===
param_grid = {
    'C': [0.1, 1, 10],
    'solver': ['lbfgs', 'liblinear']
}

grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)
print("Best CV accuracy:", grid_search.best_score_)

# Use best model
best_lr_model = grid_search.best_estimator_
y_pred_best = best_lr_model.predict(X_test)
print("Optimized Logistic Regression Test Accuracy:", accuracy_score(y_test, y_pred_best))

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from sklearn.preprocessing import LabelEncoder

# ===  Encode labels ===
le = LabelEncoder()
y_train_enc = le.fit_transform(y_train)
y_test_enc = le.transform(y_test)

# === Tokenize text ===
max_words = 10000   # vocabulary size
max_len = 100       # max words per review

tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(train_df['clean_review'])

X_train_seq = tokenizer.texts_to_sequences(train_df['clean_review'])
X_test_seq = tokenizer.texts_to_sequences(test_df['clean_review'])

X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')

# === Build LSTM model ===
model = Sequential([
    Embedding(input_dim=max_words, output_dim=64, input_length=max_len),
    LSTM(64, return_sequences=False),
    Dropout(0.5),
    Dense(32, activation='relu'),
    Dense(len(le.classes_), activation='softmax')  # multi-class output
])

model.compile(loss='sparse_categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model.summary()

# === Train model ===
history = model.fit(X_train_pad, y_train_enc,
                    epochs=5,  # increase for better accuracy
                    batch_size=32,
                    validation_split=0.2)

# === Evaluate model ===
loss, acc = model.evaluate(X_test_pad, y_test_enc)
print("LSTM Test Accuracy:", acc)

# === Predict and confusion matrix ===
y_pred_lstm = model.predict(X_test_pad)
y_pred_classes = y_pred_lstm.argmax(axis=1)

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

print("Classification Report: ", classification_report(y_test_enc, y_pred_classes))

cm = confusion_matrix(y_test_enc, y_pred_classes)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('LSTM Confusion Matrix')
plt.show()

# === Save the model ===
model.save("sentiment_lstm_model.h5")
print("LSTM model saved as sentiment_lstm_model.h5")